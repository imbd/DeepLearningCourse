{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from xml.dom import minidom\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "category_id = {category[\"name\"]: category[\"id\"] for category in categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM = 100\n",
    "\n",
    "ANNOTATIONS_PATH=\"VOCdevkit/VOC2012/Annotations/\"\n",
    "PATH_TO_TEST_IMAGES_DIR = 'VOCdevkit/VOC2012/JPEGImages'\n",
    "PATH_TO_HELP_DIR = 'VOCdevkit/VOC2012/ImageSets/Main/'\n",
    "with open(PATH_TO_HELP_DIR + 'train.txt') as f:\n",
    "    train_names = f.read().splitlines()\n",
    "train_names = train_names[:TRAIN_NUM]\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, train_names[i] + '.jpg') for i in range(len(train_names)) ]\n",
    "\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_el(box, el_list, w, h):\n",
    "    l = []\n",
    "    cur_dim = w\n",
    "    for el_name in el_list:\n",
    "        if el_name[0] == 'x':\n",
    "            cur_dim = w\n",
    "        else:\n",
    "            cur_dim = h\n",
    "        l.append(float(box.getElementsByTagName(el_name)[0].firstChild.data)/cur_dim)\n",
    "    return l\n",
    "\n",
    "def get_objects(filepath, im_shape):\n",
    "    w = im_shape[1]\n",
    "    h = im_shape[0]\n",
    "    corners = ['ymin', 'xmin', 'ymax', 'xmax']\n",
    "    xmldoc = minidom.parse(filepath)\n",
    "    all_objects = []\n",
    "    objects = xmldoc.getElementsByTagName('object')\n",
    "    for obj in objects:\n",
    "        nm = obj.getElementsByTagName('name')\n",
    "        bndbox = obj.getElementsByTagName('bndbox')    \n",
    "        all_objects.append((get_box_el(bndbox[0], corners, w, h), nm[0].firstChild.data))\n",
    "        \n",
    "    return all_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_area(s):    \n",
    "    return (s[2] - s[0]) * (s[3] - s[1])\n",
    "\n",
    "def intersection_area(a, b):\n",
    "    dx = min(a[2], b[2]) - max(a[0], b[0])\n",
    "    dy = min(a[3], b[3]) - max(a[1], b[1])\n",
    "    if (dx >= 0) and (dy >= 0):\n",
    "        return dx * dy\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def IoU(box_1, box_2):\n",
    "    return intersection_area(box_1, box_2) / (get_area(box_1) + get_area(box_2) - intersection_area(box_1, box_2))\n",
    "\n",
    "def get_IoU(objects, boxes, scores, classes):\n",
    "    l = []\n",
    "    for obj in objects:\n",
    "        if category_id.get(obj[1]) is None:\n",
    "            continue\n",
    "        cur_max = 0\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] < 0.5:                \n",
    "                break              \n",
    "            if category_id.get(obj[1]) == classes[i]:# and IoU(boxes[i], obj[0]) > 0.5:\n",
    "                cur_max = max(cur_max, IoU(boxes[i], obj[0]))                \n",
    "        l.append(cur_max)\n",
    "    return l\n",
    "\n",
    "def get_mAP(objects, boxes, scores, classes):\n",
    "    l = []\n",
    "    for obj in objects:\n",
    "        if category_id.get(obj[1]) is None:\n",
    "            continue\n",
    "        cur_max = 0\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] < 0.5:                \n",
    "                break                        \n",
    "            if category_id.get(obj[1]) == classes[i] and IoU(boxes[i], obj[0]) > 0.5:\n",
    "                cur_max = 1\n",
    "                break\n",
    "        l.append(cur_max)\n",
    "    return l\n",
    "\n",
    "def get_acc(objects, boxes, scores, classes):\n",
    "    l = []\n",
    "    for obj in objects:\n",
    "        if category_id.get(obj[1]) is None:\n",
    "            continue\n",
    "        cur_max = 0\n",
    "        for i in range(len(boxes)):\n",
    "            if scores[i] < 0.5:                \n",
    "                break                        \n",
    "            if category_id.get(obj[1]) == classes[i]:\n",
    "                cur_max = 1\n",
    "                break\n",
    "        l.append(cur_max)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU: 0.464725888225\n",
      "mAP: 52.7%\n",
      "Accuracy: 75.2%\n"
     ]
    }
   ],
   "source": [
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph,config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        all_IoU = []\n",
    "        all_mAP = []\n",
    "        all_acc = []\n",
    "        for image_path in TEST_IMAGE_PATHS:\n",
    "            file_name = image_path[image_path.rfind('/')+1:image_path.rfind('.')] + '.xml'\n",
    "            image = Image.open(image_path)\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            objects = get_objects(ANNOTATIONS_PATH + file_name, image_np.shape)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "          \n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "              [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})            \n",
    "                        \n",
    "            all_IoU += get_IoU(objects, boxes[0], scores[0], classes[0])\n",
    "            all_mAP += get_mAP(objects, boxes[0], scores[0], classes[0])\n",
    "            all_acc += get_acc(objects, boxes[0], scores[0], classes[0])\n",
    "        \n",
    "        print('Mean IoU:', np.mean(all_IoU))\n",
    "        print('mAP:', '{:.1%}'.format(np.mean(all_mAP)))\n",
    "        print('Accuracy:', '{:.1%}'.format(np.mean(all_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
